:imagesdir: images
:last-update-label!:
:stem:

= Atividades da Unidade I =
by Pablio Martins

== Atividade 01 ==
=== *Etapa 01* ===
Esta primeira atividade deverá solicitar do usuário dois pontos, localizados dentro dos limites do tamanho de uma imagem, e exibir o negativo da imagem no interior do retangulo formado por esses dois pontos.

O código esctrito na linguagem C++ pode ser visto a seguir clicando em *Show Code*:

.Show Code
[%collapsible]
====
[source, cpp]
.regions.cpp
----
include::codes/regions.cpp[]
----
====

O resultado é:

[.float-group]
--
[.left]
.Imagem Original
image::biel.png[A, 240]

[.left]
.Imagem Com Negativo
image::regions.png[B, 240]
--

====
Comentários:

A linha a seguir é responsável pela leitura da imagem em tons de cinza, evidenciado pelo parametro *IMREAD_GRAYSCALE*.
[source, cpp]
----
image = cv::imread("./img/biel.png", cv::IMREAD_GRAYSCALE);
----

Seguindo no código temos a declaração de:
[source, cpp]
----
cv::Vec2i first_point;
cv::Vec2i second_point;
----
Que são vetores com duas posições do tipo inteiro que armazenarão os pontos fornecidos pelo usuário.

Uma estrutura semelhate a:
[source, cpp]
----
do{
        std::cout << "Digite a coordenada 'x' do primero ponto (0 a " <<  image.rows << ")" << std::endl;
        std::cin >> first_point[0];
        if(first_point[0] < 0 || first_point[0] >= image.rows)
            std::cout << "O valor deve ser entre 0 e " << image.rows << std::endl;
} while (first_point[0] < 0 || first_point[0] >= image.rows);
----
é feita para cada coordenada dos pontos fornecidos pelo usuário, afim de garantir que o ponto estará dentro dos limites da imagem.

A estrutura de código seguinte é responsável por garantir que a posição da coordenadas *x* do *ponto 1* seja menor que a posição da coordenada *x* do *ponto 2*, o mesmo artifício é aplicado na coodenanda *y*.
[source, cpp]
----
if(first_point[0] < second_point[0]){
    x_smaller = first_point[0];
    x_bigger = second_point[0];
} 
else {
    x_smaller = second_point[0];
    x_bigger = first_point[0];
}
----

Nesta próxima etapa do codigo, é feita uma varredura por todo bloco retangular obitido dos dois pontos fornecido, troca-se o pixel atual por seu valor inverso. O valor inverso é dado pela subtração do valor máximo da representação da cor (255) com o valor atual do pixel.
[source, cpp]
----
for( int i = x_smaller; i < x_bigger; i++){
    for(int j = y_smaller; j < y_bigger; j++){
        image.at<uchar>(i,j) = 255 - image.at<uchar>(i,j);
    }
}
----
====

=== Etapa 02 ===

Nesta Segunda etapa da *atividade 01* o programa deverá trocar os quadrantes da diagonal na imagem.

Nesse sentido, o código implementado pode ser vista abaixo:

.Show Code
[%collapsible]
====
[source, cpp]
.replaceregions.cpp
----
include::codes/replaceregions.cpp[]
----
====

Os resultados são:

[.float-group]
--
[.left]
.Imagem Original
image::biel.png[A, 240]

[.left]
.Imagem diagonais trocadas
image::repleaceregions.png[B, 240]
--

====
Comentário:

O trecho de código abaixo inicializa uma matriz com as proporções da imagem original, em que todas as posições da matriz são preenchidas com zero. Nota-se também que a matriz criada é *unsigned char de 8 bits* e com apenas um canal, conforme mostra o parametro *CV_8UC1*.
[source, cpp]
----
image_result = cv::Mat::zeros(image_height, image_width, CV_8UC1);
----

O próximo bloco de código realiza a troca dos quadrantes da imagem. Com o centro posicionado no meio da figura o método *Rect* copia quadros para a variável *image_result* posisionando-os nos quadrantes de forma a produzir a inversão.
[source, cpp]
----
image(cv::Rect(0,0,image_width/2,image_height/2))
    .copyTo(image_result(cv::Rect(image_width/2, image_height/2,image_width/2, image_height/2)));
image(cv::Rect(image_width/2, image_height/2,image_width/2, image_height/2))
    .copyTo(image_result(cv::Rect(0, 0,image_width/2, image_height/2)));
image(cv::Rect(image_width/2, 0,image_width/2, image_height/2))
    .copyTo(image_result(cv::Rect(0, image_width/2,image_width/2, image_height/2)));
image(cv::Rect(0, image_height/2,image_width/2, image_height/2))
    .copyTo(image_result(cv::Rect(image_width/2, 0,image_width/2, image_height/2)));
----
====

== Atividade 02 ==

A segunda atividade consiste em criar uma imagem com dimensões 256x256 pixels contendo uma senóide de 4 períodos e com amplitude de 127 desenhada na horizonal. A imagem gerada deve ser salva em PNG e em YML. Um gráfico deve ser gerado mostrando a diferença entre uma imagem e a outra ao percorrer uma linha da matriz de cada imagem.

.Show Code
[%collapsible]
====
[source, cpp]
.filestorage.cpp
----
include::codes/filestorage.cpp[]
----
====

O resultado é:

[.float-group]
--
[.left]
.Imagem gerada (PNG)
image::senoide-256.png[A, 240]
--

====
Comentários:

====

== Atividade 03 ==
Esta Atividade propõe a recuperação de uma imagem codificada de uma imagem resultante. Os bits menos significantes de uma imagem são subistituídos por bits mais significantes de outra imagem, fazendo assim com que uma imagem fique oculta em outra.

.Show Code
[%collapsible]
====
[source, cpp]
.esteg-encode.cpp
----
include::codes/esteg-encode.cpp[]
----
====

O resultado é:

[.float-group]
--
[.left]
.Imagem Codificada
image::desafio-esteganografia.png[A, 240]

[.left]
.Imagem Descodificada
image::esteganografia.png[B, 240]
--

====
Comentário:

O trecho exposto logo abaixo faz a inicialização de uma matriz de três canais com valores zerados nas dimensões da imagem original. Essa matriz irá armazenar os bits menos significativos da imagem original, e revelar qual a imagem está escondida.
[source, cpp]
----
imagemEscondida = cv::Mat::zeros(imagemCodificada.rows, imagemCodificada.cols, CV_8UC3);
----

No trecho seguinte é feito uma varredura por toda a matriz da imagem original, é coletando apenas os *3 bits* menos significativos e efetuando um deslocamento de *5 bits a direita* para posicioná-los nas posições significativas da representação binária. Assim, é possível exibir a imagem escondida. 
[source, cpp]
----
for (int i = 0; i < imagemCodificada.rows; i++) {
    for (int j = 0; j < imagemCodificada.cols; j++) {
        valCodificada = imagemCodificada.at<cv::Vec3b>(i, j);
        valEscondida[0] = (0b00000111 & valCodificada[0]) << 5;
        valEscondida[1] = (0b00000111 & valCodificada[1]) << 5;
        valEscondida[2] = (0b00000111 & valCodificada[2]) << 5;
        imagemEscondida.at<cv::Vec3b>(i, j) = valEscondida;
    }
}
----
====

== Atividade 04 ==

=== Etapa 01 ===

Nesta Atividade propõe-se que seja discutido a rotulação com tons de objetos em uma cena. Nos casos em que a rotulação ocorre em imagens com menos de 255 objetos em uma cena, a escala de cinza se mostra uma forte aliada, mas e para imagens que extrapolam esse valor? +
Para resolver esse problema poderiamos adicionar componentes de cor, por exemplo o sistema RGB, assim haveria *255x255x255* possibilidades de marcação dos objetos em cena.

=== Etapa 02 ===

A segunda etapa consiste em codificar um identificador de regiões com ou sem buracos internos que existam em uma cena. abaixo está a cena em estudo.

[.float-group]
--
[.left]
.Bolhas
image::bolhas.png[A, 240]
--

As regiões que tocam as bordas devem ser desconsideradas.

.Show Code
[%collapsible]
====
[source, cpp]
.labeling.cpp
----
include::codes/labeling.cpp[]
----
====

====
Comentários:

Para realizar a remoção dos objetos que tocam as bordas, foi executado uma varredura nas bordas da figura a procura de pixels brancos. O trecho abaixo mostra as instruções realizadas.

[source, cpp]
----
for(int i = 0; i < height; i++){        
    if(image.at<uchar>(i,0) == 255){
        pointWhite.x = 0;
        pointWhite.y = i;
        cv::floodFill(image, pointWhite, 0);
    }
    if(image.at<uchar>(i, height-1) == 255){
        pointWhite.x = height-1;
        pointWhite.y = i;
        cv::floodFill(image, pointWhite, 0);
    }
}

for(int i = 0; i < width; i++){
    if(image.at<uchar>(0,i) == 255){
        pointWhite.x = i;
        pointWhite.y = 0;
        cv::floodFill(image, pointWhite, 0);
    }
    if(image.at<uchar>(width-1, i) == 255){
        pointWhite.x = i;
        pointWhite.y = width-1;
        cv::floodFill(image, pointWhite, 0);
    }
}
----

Como resultado temos:

[.float-group]
--
[.left]
.Bolhas sem elementos nas bordas
image::labeling_borda.png[A, 240]
--

Em seguida faz-se a contagem de elementos dentro da cena, usando diferentes tons de cinza para marcar os elementos ja computados. O trecho abaixo mostra as instruções executadas para essa tarefa.

[source, cpp]
----
numberObjects = 0;
for(int i = 0; i < height; i++){
    for(int j = 0; j < width; j++){
        if(image.at<uchar>(i, j) == 255){
            numberObjects++;
            pointWhite.x = j;
            pointWhite.y = i;
            cv::floodFill(image, pointWhite, numberObjects);
        }
    }
}
----

Como resultado temos:

[.float-group]
--
[.left]
.Bolhas com rotulação
image::labeling.png[A, 240]
--

O próximo passo é tornar todo o fundo branco. 

[source, cpp]
----
cv::floodFill(image, cv::Point(0,0), 255);
----

O resultado apresentado é:

[.float-group]
--
[.left]
.Bolhas com rotulação
image::labeling_fundo.png[A, 240]
--

Agora vamos identificar, contar e remover as bolhas que tenham 1 ou mais buracos. O trecho seguinte é responsável por essa tarefa.

[source, cpp]
----
donut = 0;
for(int i = 0; i < height; i++){
    for(int j = 1; j < width; j++){
        if(image.at<uchar>(i, j) == 0){
            if(image.at<uchar>(i,j-1) != 255){
                donut++;
                cv::floodFill(image, cv::Point(j,i), 255);
                cv::floodFill(image, cv::Point(j-1,i), 255);
            }
            else{
                cv::floodFill(image, cv::Point(j,i), 255);
            }           
        }
    }
}
----

Feito o passo anterior restam apenas as regiões que não contêm buracos.

[.float-group]
--
[.left]
.Bolhas sem regiões com buraco
image::labeling_no_donut.png[A, 240]
--

Por fim é feito a contagem das bolhas sem buraco. Segue o trecho do código.

[source, cpp]
----
bubbles = 0;
for(int i = 0; i < height; i++){
    for(int j = 0; j < width; j++){
        if(image.at<uchar>(i, j) != 255){
            bubbles++;
            cv::floodFill(image, cv::Point(j,i), 255);      
        }
    }
}
----
Como saída final do código, para a figura *bolhas.png*, temos: +
Total de Objetos: 21 +
Total de Rosquinha: 7 +
Total de Bolhas: 14 +
====

== Atividade 05 ==
=== Etapa 01 ===
Esta atividade busca realizar a equalização do histograma durante a captura de uma câmera.

.Show Code
[%collapsible]
====
[source, cpp]
.equalize.cpp
----
include::codes/equalize.cpp[]
----
====
.Video Normal/Equalizador
video::TYsMKFstamg[youtube]

====
Comentários:

Várias declarações são feita logo nas linhas iniciais da função *main*, dentre elas a variável *cap*. *cap* é um objeto do tipo *VideoCapture* responsável por receber um fluxo de frames de uma determinado dispositivo de vídeo. Para execução desse código foi utilizado a webcam embutida no notebook e a sua inicialização é feita através do seguinte comando:
[source, cpp]
----
cap.open(0);
----

Em seguida, é feito uma configuração no tamanhos dos frames a serem capturados pela câmera. Trecho a seguir:
[source, cpp]
----
cap.set(cv::CAP_PROP_FRAME_WIDTH, 640);
cap.set(cv::CAP_PROP_FRAME_HEIGHT, 480);
----

As linhas de código:
[source, cpp]
----
cv::Mat histImgGray(histh, histw, CV_8UC1, cv::Scalar(0));
cv::Mat histImgGrayEq(histh, histw, CV_8UC1, cv::Scalar(0));
----
são matrizes que irão armazenar informações do histograma. Nesse trecho acima, as duas matrizes são declaradas e instanciadas, todas as posições delas são atribuidas o valor 0.

A captura de um frame do fluxo é feita por:
[source, cpp]
----
cap >> image;
----
Logo em seguida, o frame capturado é convertido para uma imagem em tons de cinza, nota-se que o frame obtido inicialmente está no padrão RGB. Segue a linha responsável por essa tarefa.
[source, cpp]
----
cv::cvtColor(image, image_gray, cv::COLOR_BGR2GRAY);
----

Em seguida temos a equalização do histograma que é feita pela função *histogram_equalization*:
[source, cpp]
----
void histogram_equaliation(cv::Mat imageInput, cv::Mat *imageOutput){
    int histogram[256], histogram_accumulate[256];
    float alpha = 255.0/(imageInput.cols * imageInput.rows);

    histogram_computation(imageInput, histogram);
    histogram_accumulate[0] = alpha * histogram[0];
    for(int i = 1; i < 256; i++){
        histogram_accumulate[i] = histogram_accumulate[i-1] + (alpha * histogram[i]);
    }
    
    for(int i = 0; i < imageInput.rows; i++){
        for(int j = 0; j < imageInput.cols; j++){
            (*imageOutput).at<uchar>(i,j) = histogram_accumulate[imageInput.at<uchar>(i,j)];
        }
    }
}
----
Basicamente a função acima faz o cálculo do histograma acumulado ponderando cada ponto por um fator *alpha*. O *alpha* é obtido dividindo o valor de cor máximo (255) pela quantidade de pixels da imagem. De posse do histograma aculmulado e feito o mapeamento de cada pixel da imagem no histograma aculmulado, gerando assim um novo frame equalizado.

Nas linhas seguintes são feitas: o cálculo do histograma (com a funcão *calcHist* do pacote do opencv), a normalização e o preechimento das matrizes que serão utilizadas para desenhar o histograma na janela de exibição.
[source, cpp]
----
cv::calcHist(&image_gray, 1, 0, cv::Mat(), histGray, 1,
             &nbins, &histrange,
             uniform, acummulate);
cv::calcHist(&image_gray_equalization, 1, 0, cv::Mat(), histGrayEq, 1,
             &nbins, &histrange,
             uniform, acummulate);

cv::normalize(histGray, histGray, 0, histImgGray.rows, cv::NORM_MINMAX, -1, cv::Mat());
cv::normalize(histGrayEq, histGrayEq, 0, histImgGrayEq.rows, cv::NORM_MINMAX, -1, cv::Mat());

histImgGray.setTo(cv::Scalar(0));
histImgGrayEq.setTo(cv::Scalar(0));

for(int i=0; i<nbins; i++){
    cv::line(histImgGray,
    cv::Point(i, histh),
    cv::Point(i, histh-cvRound(histGray.at<float>(i))),
    cv::Scalar(255), 1, 8, 0);
    cv::line(histImgGrayEq,
    cv::Point(i, histh),
    cv::Point(i, histh-cvRound(histGrayEq.at<float>(i))),
    cv::Scalar(255), 1, 8, 0);
}

histImgGray.copyTo(image_gray(cv::Rect(0, 0,nbins, histh)));
histImgGrayEq.copyTo(image_gray_equalization(cv::Rect(0, 0,nbins, histh)));
----

A exibição do fluxo de vídeo e feita por:
[source, cpp]
----
cv::imshow("Image Normal", image_gray);
cv::imshow("Equalizado", image_gray_equalization);
----
====
=== Etapa 02 ===
Nesta segunda etapa é proposto a realização de um detector de movimento. Sua implementação deu-se comparando um histograma passado com um corrente, foi usado apenas um canal de cor, nesse caso o vermelho.

O código implementado:

.Show Code
[%collapsible]
====
[source, cpp]
.motiondetector.cpp
----
include::codes/motiondetector.cpp[]
----
====
.Video Detector de Movimento
video::x0OueLljhzE[youtube]

====
Comentários:

Basicamente foi adicionado uma função que compara o histograma de um frame anterior com o atual.

[source, cpp]
----
bool move_detection(cv::Mat hist_current, cv::Mat hist_old, int limiar){
    double erro = 0;
    
    for(int i=0; i < 256; i++){
        if(hist_current.at<u_int8_t>(i) != 0)
            erro += abs((hist_current.at<u_int8_t>(i) - hist_old.at<u_int8_t>(i))/double(hist_current.at<u_int8_t>(i)));
    }
    erro = erro/256.0;
    if(erro > limiar)
        return true;
    else 
        return false;
}
----

Essa função faz uma soma do erro entre todos os tons presente no histograma atual e antigo de forma culmulativa, e posteriormente divide pela quantidade de tons. Caso o valor desse erro esteja maior que um limiar a função retorna *true*, caso contrário retorna *false*. +
A chamada da função na main é:

[source, cpp]
----
if(!histR_old.empty() && move_detection(histR, histR_old, limiar)){
            cv::putText(
                image, 
                "Move Detect",
                cv::Point2d(height/2, width/2),
                cv::FONT_HERSHEY_SIMPLEX,
                1,
                cv::Scalar(0,0,255)
            );
        }
----

Sendo assim, caso seja detectado o movimento na cena é desenhado o texto *Move Detect* na tela.
====

== Atividade 06  ==
 
Nessa atividade deseja-se que seja adicionado a um código já existente, uma nova funcionalidade. Nesse caso o cálculo do laplaciano do gaussiano.

.Show Code
[%collapsible]
====
[source, cpp]
.laplgauss.cpp
----
include::codes/laplgauss.cpp[]
----
====
.Video Laplacian - Gauss
video::tcLRgt_L_Ak[youtube]

====
Comentários:

Basicamento, foi adicionado ao código um vetor de máscara.
[source, cpp]
----
std::vector<cv::Mat> mask = {cv::Mat(3, 3, CV_32F), cv::Mat(3,3,CV_32F)};
----

Quando, durante a execução do código, for precionado a tecla "*e*" seria aplicado dois filtros, o lapalacian e o gauss. Esse trecho de código é responsável por essa funcionalidas.
[source, cpp]
----
case 'e':
    mask[0] = cv::Mat(3, 3, CV_32F, laplacian);
    mask[1] = cv::Mat(3, 3, CV_32F, gauss);
    nameFilter[0] = "filtroespacial";
    nameFilter[1] = "Laplacian - Gauss";
    qtd_filter = 2;
    break;
----

Um loop *for* é responsável por aplicar os dois filtros no frame.
[source, cpp]
----
for(int i = 0; i < qtd_filter; i++){
    cv::filter2D(frame32f, frameFiltered, frame32f.depth(), mask[i], cv::Point(1, 1), 0);        
    if (absolut) {
        frameFiltered = cv::abs(frameFiltered);
    }
    frameFiltered.convertTo(result, CV_8U);
    cv::imshow(nameFilter[i], result);
    frameFiltered.copyTo(frame32f);
}
----

Ao observar o filtro laplaciano puro e posteriormente com aplicação do filtro de gauss, podemos notar uma redução do ruído. Note, a imagem abaixo não está com valores absolutos para os pixels.

[.float-group]
--
[.left]
.Laplacian vs laplacian-Gauss (no absolut)
image::laplgauss_noabs.png[A, 640]
--

Ao habilitar os valores absolutos, temos uma melhora mais significativa com a redução melhor do ruído.
[.float-group]
--
[.left]
.Laplacian vs laplacian-Gauss (absolut)
image::laplgauss_abs.png[A, 640]
-- 
====

== Atividade 07 ==

Esta atividade consiste na implementação do efeito de ilusão ótica de miniaturização. Devem ser implementados: Ajuste de altura de foco; Ajuste de Decaimento; Posicionamento vertical do foco.

O tiltshift trabalha com duas imagens de ponderação:

[.float-group]
--
[.left]
.Exemplo de imagens geradas para ponderação
image::pondera.jpeg[A, 350]
--
Ambas imagens acima são geradas para  que seja ponderado os pixels da imagem borrada e da imagem sem borramento para simular o efeito tiltshift.

Para a geração dessas imagens foi utilizado a seguinte expressão matemática:

.Equação
[stem]
++++
\alpha(x) = \frac{1}{2} \left( tanh \frac{x - l1}{d} - tanh \frac{x - l2}{d} \right)
++++
Sendo, l1 e l2 pontos centrais em que ocorre a transição 0 para 1 e de 1 para 0, respectivamente, e d a taxa de decaimento, ou seja, o qual rapida é a transição.

O código implementado segue logo abaixo.

.Show Code
[%collapsible]
====
[source, cpp]
.tiltshift.cpp
----
include::codes/tiltshift.cpp[]
----
====

Como resultado temos:

[.float-group]
--
[.left]
.imagem sp.png
image::sp.png[A, 350]

[.left]
.imagem sp.png com tiltshift
image::atv_07.png[B, 350]
--

====
Comentários:

Para produção do efeito precisaremos da imagem normal e a borrada. Para obter a imagem borrada foi ultilizado o filtro gaussiano com kernel 17x17, a escolha desse kernel foi por ficar visualmente mais agradável. segue a chamada do filtro:
[source, cpp]
----
cv::GaussianBlur(image, image_blurred, cv::Size2i(17,17), 0);
----

Seguindo nos comentários do código temos a função *show_img()*, essa é a função que produzirá o efeito tiltshift. É iniciado com a declaração de duas matrizes:
[source, cpp]
----
cv::Mat weighting_mask(image_height, image_width, CV_32FC3);
cv::Mat weighting_mask_inverse(image_height, image_width, CV_32FC3);
----
essas duas vão armazenar as matrizes de ponderação. +
seguindo na função temos o calculo dos fatores de ponderação para cada linha da matriz de ponderação:

[source, cpp]
----
for(int i = 0; i < image_height; i++){
    if (decay != 0){
      line_value = 0.5*(tanh((i + vertical_position - point_down)/decay) - tanh((i + vertical_position - point_up)/decay));
      line_value_inverse = 1.0 - line_value;
    }
    else { 
      line_value = 1.0;
      line_value_inverse = 0.0;
    }

    for(int j = 0; j < image_width; j++){
      weighting_mask.at<cv::Vec3f>(i, j) = cv::Vec3f(line_value, line_value, line_value);
      weighting_mask_inverse.at<cv::Vec3f>(i, j) = cv::Vec3f(line_value_inverse, line_value_inverse, line_value_inverse);
    }
}
----
atenta-se para o valor de decaimento que pode assumir o valor 0 e incorrer em um erro de divisão por 0. Isso justifica a adição de um *if* para tratar esse problema.

O próximo trecho da função é responsável por realizar a ponderação das imagens normal e borrada com as matrizes de ponderação geradas, para logo em seguida realizar a união das duas imagens e fazer sua exibição.
[source, cpp]
----
cv::Mat result_normal, result_inverse;

cv::multiply(image, weighting_mask, result_normal);
cv::multiply(image_blurred, weighting_mask_inverse, result_inverse);
  
cv::addWeighted(result_normal, 1.0, result_inverse, 1.0, 0.0, result);

result.convertTo(result, CV_8UC3);
  
cv::imshow("Tiltshift", result);
----

Os sliders são gerados com o método *createTrackbar* disponíveis jundo ao pacote do *opencv*.
====