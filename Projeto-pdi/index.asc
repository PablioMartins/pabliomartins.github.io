:imagesdir: img
:last-update-label!:
:stem:

= Projeto dae Processamento Digital de Imagens - PDI =
by Pablio Martins

----
Este trabalho contempla a atividade avaliativa da unidade III da disciplina de Processamento Digital de Imagens, ofertado pelo Departamento de Computação e Automação da Universidade Federal do Rio Grande do Norte no semeste 2023.2. A disciplina tem como docente AGOSTINHO DE MEDEIROS BRITO JUNIOR.
----

== Introdução ==

O programa desenvolvido neste projeto busca extrair objetos de uma imagem. Neste caso, caracteres dispostos em uma imagem, conforme é mostrado abaixo:

.Imagem
image::input.jpg[A, 400]

Para que o algoritmo funcione corretamento é necessário que os objetos e o fundo sejam separáveis, não haja ruídos e os objetos não devem se localizar nas bordas da imagem. Há, também, outro fator que não foi considerado, as letras que possuem duas regiões distitas, como a letra "i" minúscula e as letras acentuadas. Logo, este algoritmo é voltado a apenas letras com regiões totalmente conectadas.

== Desenvolvimento ==

O código completo implementado pode ser visto logo abaixo, ao clicar em Show Code:

.Show Code
[%collapsible]
====
[source, cpp]
.regions.cpp
----
include::objects.cpp[]
----
====

Agora vamos detalhar as linha do código bem como a sua execução.

=== Execução ===

Para compilar o código podemos usar um arquivo Makefile, que contém os seguintes parametros:

[source, makefile]
.makefile
----
include::makefile[]
----

Assim, basta digitar o seguinte comando no terminal (lembre-se estar no diretório corrente que têm os arquivos *objects.cpp* e *makefile*, e de ter suporte a biblioteca do *opencv*):

[source, bash]
----
make objects
----

Para a correta execução do programa será necessário também criar um diretório chamado de "img" no mesmo local que está o executável do código. Esse diretório será o local que irá receber os objetos extraídos da imagem. Depois de criado o driretório, a execução do programa pode ser efetudado com:

[source, bash]
----
./objects caminho_da_imagem_de_entrada
----

Após a execução do código todos os objetos presentes na imagem serão individualizados em novas imagens que estarão no diretório criado ("img/").

=== O Código ===

Iniciaremos a discursão  apartir da função *main*. A função inicia-se com a declaração das variáveis que vão armazenar a imagem e o resultado de sua binarização, *image_gray* e *image_binary*. Logo em seguida, são declarados o limiar que será usado na binarização, assim como o valor máximo que poderá ser assumido na binarização. 
[source, cpp]
----
cv::Mat image_gray, image_binary;
double limiar = 128.0;
double valMax = 255.0;
----

A próxima linha é responsável por carregar a imagem fornecida como parâmetro de entrada na execução do programa.

[source, cpp]
----
image_gray = cv::imread(argv[1], cv::IMREAD_GRAYSCALE);
----

Seguindo na função, é realizado um teste no carregamento da imagem para avaliar se houve a correta execução do comando anterior.

[source, cpp]
----
if (image_gray.empty()) {
        std::cout << "Erro abrindo imagem" << argv[1] << std::endl;
        return EXIT_FAILURE;
    }
----

De posse da imagem, é feito a binarização com a função *threshold* do opencv. Os parametros fornecidos são: a imagem de entrada, a imagem de saída, o limiar, o valor máximo e o tipo de binarização.

[source, cpp]
----
cv::threshold(image_gray, image_binary, limiar, valMax, cv::THRESH_BINARY);
----

Seguindo, temos a função que foi implementada *cut_out_object*. Essa função pede como parâmetro apenas a imagem de entrada e é necessário que essa imagem seja binária, ou seja, tenha valores 0 ou 255 em seus pixels.

[source, cpp]
----
cut_out_object(image_binary);
----

A função *cut_out_object* é responsável por varrer a imagem a procura de pixels pretos (valor 0) em pontos ainda não visitados. Ao encontrar ela chama a função *extract_object* passando como parâmetro esse pixel.

Analizando as linhas de código da função *cut_out_object* temos:

[source, cpp]
----
cv::Mat visited(image_binary_input.rows, image_binary_input.cols, CV_8U, cv::Scalar(0));
int num_object_current=0;
----

Essa linha acima cria uma matriz que contém as mesmas dimenções da imagem, e servirá como guia para saber quais pixels já foram visitados pelo algoritmo. A variável *num_object_current* irá armazenar a quantidade de elementos encontrados na imagem.

[source, cpp]
----
for(int i=1; i < image_binary_input.rows-1; i++){
    for(int j=1; j < image_binary_input.cols-1; j++){
        if(visited.at<uchar>(i,j) == 0){
            visited.at<uchar>(i,j) = 1;
            if(image_binary_input.at<uchar>(i,j) == 0){
                extract_object(image_binary_input , &visited, cv::Point2d(i, j), &num_object_current);
            }
        }
    }
}
----

O laço exposto, tem o objetivo de percorre a imagem marcando como visitado, através da matriz *visited*, e procurando pixels pretos (com valor 0). Ao encontrar um pixel que não foi visitidado e preto é chamada a função *extract_object* que tem como parâmetros de entrada: a imagem binária, a matriz de visitados, o ponto atual e a quantidade de objetos já encontrados.

A função *extract_object* e responsável por identificar os pixels que limitam o objeto, formando um retângulo no entorno do objeto para extraí-lo.

Detalhando um pouco mais a função temos, no seu início:

[source, cpp]
----
int x_low, y_low, x_hight, y_hight, x_current, y_current, point;
    std::string file_name;
----

As variáveis *x_low* e *y_low* armazenarão os valores do canto superor esquedo do retângulo, ou seja, os menores valores de x e y para o retângulo que delimita o objeto. Já *x_hight* e *y_hight* armazenam os maiores valores de x e y. *x_current* e *y_current* são variáveis que vão guardar o ponto que está sendo processado, e, por fim, point irá armazenar o valor do pixel atualmente processado. *file_name* será usado para gerar o nome do objeto e salva-lo.


Para a implementação desse algoritmo foi usado o algoritmo seguidor de fronteira de forma adaptada. Basicamente foi cridado estados, por meio de uma tipo de dado (*enum*) e definida uma operação de soma.

[source, cpp]
----
enum StatesBorder {T1, T2, T3, T4, T5, T7, T8};

StatesBorder operator+(StatesBorder state, int increment){
    return static_cast<StatesBorder>((static_cast<int>(state) + increment) % 8);
}
----

Dessa forma, haverá 8 estados "T1 ... T8" e a operação de soma que permitirá a transição de um estado para outro, de forma que: T1 + 1 = T2.

Os estados foram definidos conforme a figura abaixo, em que no centro temos o pixel atual e sua vizinhaça.

.Estados
image::estados.png[A, 250]

Foi criado um vetor com o deslocamento para cada vizinhaça a partir do ponto central:

[source, cpp]
----
std::vector<std::pair<int, int>> desloc = {
        { 0, -1}, // T1
        {-1, -1}, // T2
        {-1,  0}, // T3
        {-1,  1}, // T4
        { 0,  1}, // T5
        { 1,  1}, // T6
        { 1,  0}, // T7
        { 1, -1}  // T8
};
----

O algoritmo seguidor de fronteira começa seu real processamento no loop while. Primeiramente é coletado o valor do pixel da vizinhaça correspondente ao estado atual, conforme é evidenciado na linha abaixo.

[source, cpp]
----
point = image_input.at<uchar>(x_current + desloc[state].first, y_current + desloc[state].second);
----

A variável *point* é testada:

[source, cpp]
----
if(point == 0){ 
    ...
}
else {
    neighborhood_check++;
    state = state + 1; 
}
----

Caso o seu valor seja diferente de 0 é chamado o próximo estado. Um detalhe importante é que caso seja um único pixel cercado por uma vizinhaça de pixels diferentes de 0, incorreria em um travamento do programa, então, foi adicionado uma variável de controle *neighborhood_check* que interrompe o loop nesse caso. conforme linha abaixo:

[source, cpp]
----
if(neighborhood_check == 8){
    return;
}
----

Já no caso em que é encotrado um pixel preto (valor 0), o algoritmo segue alguns passos:

[source, cpp]
----
x_current = x_current + desloc[state].first;
y_current = y_current + desloc[state].second;
----

Primeiramente ele transforma o pixel do estado atual no pixel corrente, atualizando os valores de *x_current* e *y_current*.
Logo em seguida, verifica se o novo pixel corrente já foi visitado. Essa linha é o critério de parada do loop.

[source, cpp]
----
if((*visited).at<uchar>(x_current, y_current) != 0){
    break;
}
----

Seguindo, é verificado se o valor novo de "x" e o novo de "y" é menor que os valores de *x_low* e *y_low* ou maior que os valores de *x_hight* e *y_hight*, e, caso seja, é feita a atualização do valor.

[source, cpp]
----
if(x_current < x_low) x_low = x_current;
if(y_current < y_low) y_low = y_current;
if(y_current > y_hight) y_hight = y_current;
if(x_current > x_hight) x_hight = x_current;
----

A próxima linha marca o novo pixel como visitado.

[source, cpp]
----
(*visited).at<uchar>(x_current, y_current) = 1;
----

Dando continuidade temos:

[source, cpp]
----
if(state == T1 || state == T3 || state == T5 || state == T7){
    state = state + 7;
} else {
    state = state + 6;
}
----

Nesse trecho do código é definido em qual estado o novo pixel irá iniciar. Há duas possibilidades, e sua definição vai depender de qual estado o novo pixel preto foi encontrado.

.Atualização do estado
image::trn_estados.png[A, 400]

Logo após a atualização do pixel corrente, quando esse está na posição do estado T5, o novo estado deverá regredir para o estado T4, pois T1, T2 e T3 já foram visitados. Observa-se que não foi definida a operação de subtração nos estados, porém, é possível, devido as transições serem ciclicas, somar 7 para chegar no estado T4. A mesma demostração é possível de ser feita  para os estados T1, T3 e T7.

Já quando o pixel foi encontrado na diagonal é necessário regredir dois estados, conforme mostra a figura.

.Atualização do estado
image::trs_estados.png[A, 400]

Assim, todo o contorno do objeto é percorrido na busca dos valores de "x" e "y" máximos e mínimos que o contornam.

Depois de encontrado esses valores, é feita a marcação de todos os pixels internos ao retângulo, confome mostra o trecho abaixo.

[source, cpp]
----
for(int i = x_low; i <= x_hight; i++){
    for(int j = y_low; j <= y_hight; j++){
        (*visited).at<uchar>(i, j) = 1;
    }
}
----

Logo em seguida, é feito armazenado o objeto encontrado em uma imagem ".png".

[source, cpp]
----
file_name = "img/letter_";
file_name.append(std::to_string(*numObject));
file_name.append(".png");

std::cout << file_name << std::endl;
(*numObject)++;

cv::imwrite(file_name, image_input(cv::Rect(y_low-1, x_low-1, y_hight - y_low+3,x_hight - x_low+3)));
----

=== Resultados ===

Como saída do programa, temos a geração de imagens separadas para cada objeto. Utilizando o exemplo apresentado na introdução, algumas de suas saídas são:

[.float-group]
--
[.left]
.Primeiro objeto extraído
image::letter_0.png[]

[.left]
.Segundo objeto extraído
image::letter_1.png[]

[.left]
.Terceiro objeto extraído
image::letter_3.png[]
--

